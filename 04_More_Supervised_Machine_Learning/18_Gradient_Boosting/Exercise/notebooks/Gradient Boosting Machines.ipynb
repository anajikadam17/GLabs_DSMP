{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align=\"center\">Gradient Boosting and XGBoost</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainer Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\display.py:689: UserWarning: Consider using IPython.display.IFrame instead\n",
      "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://player.vimeo.com/video/282667268\" width=\"800\" height=\"600\" frameborder=\"0\" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('<iframe src=\"https://player.vimeo.com/video/282667268\" width=\"800\" height=\"600\" frameborder=\"0\" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Using cached https://files.pythonhosted.org/packages/5e/49/b95c037b717b4ceadc76b6e164603471225c27052d1611d5a2e832757945/xgboost-0.90-py2.py3-none-win_amd64.whl\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.16.2)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.2.1)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-0.90\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        6  \n",
       "1      9.5        6  \n",
       "2     10.1        6  \n",
       "3      9.9        6  \n",
       "4      9.9        6  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/white-wine.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('quality', 1)\n",
    "y = df.iloc[:,-1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "### Mini Challenge - 1\n",
    "***\n",
    "### Instructions\n",
    "* Split the white-wine dataset into train and test set with `test_size = 0.3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "X , y = df.iloc[:,:-1], df.iloc[:,-1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = tts(X,y,test_size=0.3,random_state =0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "### Mini Challenge - 2\n",
    "***\n",
    "\n",
    "### Instructions\n",
    "* Initialise a decision tree model(Weak Classifier) with DecisionTreeClassifier() having max_depth=1 & random_state=0 and save it to a variable called `dt_clf`.\n",
    "\n",
    "* Fit the model on the training data `x_train` and `y_train` using the `fit()` method.\n",
    "\n",
    "* Find out the accuracy score between `x_test` and `y_test` using the `score()` method and save it in a variable called `dt_score`\n",
    "\n",
    "* Initialise a AdaBoost model with AdaBoostClassifier() having base_estimator=dt_clf & random_state=0 and save it to a variable called `ada_clf`.\n",
    "\n",
    "* Fit the model on the training data `x_train` and `y_train` using the `fit()` method.\n",
    "\n",
    "* Find out the accuracy score between `x_test` and `y_test` using the `score()` method and save it in a variable called `ada_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weak Learner Score:  0.42857142857142855\n",
      "Adaboost Score:  0.4326530612244898\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#Fitting of Weak Classifier\n",
    "dt_clf = DecisionTreeClassifier(max_depth=1 , random_state=0)\n",
    "dt_clf.fit(x_train,y_train)\n",
    "dt_score = dt_clf.score(x_test,y_test)\n",
    "print(\"Weak Learner Score: \",dt_score)\n",
    "\n",
    "# Fitting of weak classifier with Adaboost\n",
    "ada_clf = AdaBoostClassifier(base_estimator=dt_clf , random_state=0)\n",
    "ada_clf.fit(x_train,y_train)\n",
    "ada_score = ada_clf.score(x_test,y_test)\n",
    "print(\"Adaboost Score: \",ada_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weak Learner Score:  0.42857142857142855\n",
      "Adaboost Score:  0.4326530612244898\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    " \n",
    "dt_clf = DecisionTreeClassifier(max_depth=1 , random_state=0)\n",
    "dt_clf.fit(X_train,y_train)\n",
    "dt_score = dt_clf.score(X_test,y_test)\n",
    "print(\"Weak Learner Score: \",dt_score)\n",
    " \n",
    "ada_clf = AdaBoostClassifier(base_estimator=dt_clf , random_state=0)\n",
    "ada_clf.fit(X_train,y_train)\n",
    "ada_score = ada_clf.score(X_test,y_test)\n",
    "print(\"Adaboost Score: \",ada_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "dt_clf = DecisionTreeClassifier(max_depth=1, random_state=0)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "dt_score = dt_clf.score(X_test, y_test)\n",
    "\n",
    "ada_clf = AdaBoostClassifier(base_estimator=dt_clf, random_state=0)\n",
    "ada_clf.fit(X_train, y_train)\n",
    "ada_score = ada_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt_score_train:  0.55950991831972\n",
      "dt_score:  0.5190476190476191\n"
     ]
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier(max_depth = 4,\n",
    "                                max_features=10,\n",
    "                                min_samples_split=15,\n",
    "                                min_samples_leaf =2,\n",
    "                                random_state=0)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "dt_score = dt_clf.score(X_train, y_train)\n",
    "print('dt_score_train: ',dt_score)\n",
    "dt_score = dt_clf.score(X_test, y_test)\n",
    "print('dt_score: ',dt_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt_score_train:  0.5708868144690782\n",
      "dt_score:  0.5272108843537415\n"
     ]
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier(max_depth = 4,\n",
    "                                max_features=10,\n",
    "                                min_samples_split=15,\n",
    "                                min_samples_leaf =2,\n",
    "                                random_state=0)\n",
    "ada_clf = AdaBoostClassifier(base_estimator=dt_clf,n_estimators=5, learning_rate=0.0015, random_state = 6)\n",
    "ada_clf.fit(X_train, y_train)\n",
    "dt_score = ada_clf.score(X_train, y_train)\n",
    "print('dt_score_train: ',dt_score)\n",
    "dt_score = ada_clf.score(X_test, y_test)\n",
    "print('dt_score: ',dt_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  0.5813885647607935\n",
      "test   0.5142857142857142\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(criterion='entropy', max_depth= 5,max_features= 'auto',n_estimators= 10)\n",
    "rfc.fit(X_train,y_train) \n",
    "print('train ',rfc.score(X_train,y_train))\n",
    "print('test  ',rfc.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
       "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
       "       'pH', 'sulphates', 'alcohol', 'quality'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['citric acid','density'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.drop(['citric acid','density'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>6.4</td>\n",
       "      <td>0.29</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.197</td>\n",
       "      <td>75.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>3.01</td>\n",
       "      <td>0.38</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4552</th>\n",
       "      <td>6.4</td>\n",
       "      <td>0.55</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0.027</td>\n",
       "      <td>20.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.73</td>\n",
       "      <td>13.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.24</td>\n",
       "      <td>15.8</td>\n",
       "      <td>0.035</td>\n",
       "      <td>46.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.51</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.51</td>\n",
       "      <td>11.3</td>\n",
       "      <td>0.034</td>\n",
       "      <td>61.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3034</th>\n",
       "      <td>6.9</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8.4</td>\n",
       "      <td>0.042</td>\n",
       "      <td>36.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.55</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  residual sugar  chlorides  \\\n",
       "196             6.4              0.29             3.6      0.197   \n",
       "4552            6.4              0.55             9.6      0.027   \n",
       "133             6.6              0.24            15.8      0.035   \n",
       "2517            7.3              0.51            11.3      0.034   \n",
       "3034            6.9              0.25             8.4      0.042   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide    pH  sulphates  alcohol  \n",
       "196                  75.0                 183.0  3.01       0.38      9.1  \n",
       "4552                 20.0                 104.0  3.22       0.73     13.1  \n",
       "133                  46.0                 188.0  3.24       0.51      9.2  \n",
       "2517                 61.0                 224.0  3.14       0.56      9.5  \n",
       "3034                 36.0                 156.0  3.15       0.55      9.4  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "### Mini Challenge - 3\n",
    "***\n",
    "\n",
    "### Instructions\n",
    "\n",
    "* Initialise a Gradient Boost model with GradientBoostingClassifier() having random_state=0 and save it to a variable called `gb_clf`.\n",
    "\n",
    "* Fit the model on the training data `x_train` and `y_train` using the `fit()` method.\n",
    "\n",
    "* Find out the accuracy score between `x_test` and `y_test` using the `score()` method and save it in a variable called `gb_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boost Score:  0.5741496598639456\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state =0)\n",
    "gb_clf.fit(x_train,y_train)\n",
    "gb_score = gb_clf.score(x_test,y_test)\n",
    "print(\"Gradient Boost Score: \",gb_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  58.92648774795799\n",
      "test   51.90476190476191\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(learning_rate=0.01, random_state = 1)\n",
    "gb_clf.fit(X_train,y_train)\n",
    "print('train ',gb_clf.score(X_train,y_train)*100)\n",
    "print('test  ',gb_clf.score(X_test,y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  58.809801633605595\n",
      "test   52.38095238095239\n"
     ]
    }
   ],
   "source": [
    "gb_clf = GradientBoostingClassifier(learning_rate=0.01, random_state = 1)\n",
    "gb_clf.fit(X_train,y_train)\n",
    "print('train ',gb_clf.score(X_train,y_train)*100)\n",
    "print('test  ',gb_clf.score(X_test,y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "### Mini Challenge - 4\n",
    "***\n",
    "### Instructions\n",
    "* For this challenge, you will have to install `xgboost` library. Import `xgboost` and instantiate `XGBClassifier()` and fit it on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "model = xgb.XGBClassifier(random_state=0)\n",
    "\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  56.68028004667445\n",
      "test   53.06122448979592\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "model = xgb.XGBClassifier(learning_rate = 0.001,random_state=0)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "print('train ',model.score(X_train,y_train)*100)\n",
    "print('test  ',model.score(X_test,y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "### Mini Challenge - 5\n",
    "***\n",
    "### Instructions\n",
    "* Predict the model on the test set and check the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5619047619047619"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "### Mini Challenge - 6\n",
    "***\n",
    "### Instructions\n",
    "* Now let's do some hyperparameter tuning by defining the parameters `'colsample_bytree': np.linspace(0.5, 0.9, 5)`,`'n_estimators':[5, 10]`,`'max_depth': [10, 15, 20, 25]` and then fit them into a GridSearchCV model with `scoring = 'neg_mean_squared_error'`and cross_ validation parameter `cv = 5`<br/><br/>Feel free to experiment on the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gbm_param_grid = {\n",
    "     'colsample_bytree': np.linspace(0.5, 0.9, 5),\n",
    "     'n_estimators':[5, 10],\n",
    "     'max_depth': [10, 15, 20, 25]\n",
    "}\n",
    "\n",
    "grid_mse = GridSearchCV(estimator = model, param_grid = gbm_param_grid, scoring = 'accuracy', cv = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "### Mini Challenge - 7\n",
    "***\n",
    "### Instructions\n",
    "* Fit the GridSearchCV model on the train dataset and get the best parametres and the Highest Accuracy found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'colsample_bytree': 0.7, 'max_depth': 20, 'n_estimators': 10}\n",
      "Highest Accuracy found:  0.6458576429404901\n"
     ]
    }
   ],
   "source": [
    "grid_mse.fit(x_train, y_train)\n",
    "print(\"Best parameters found: \",grid_mse.best_params_)\n",
    "print(\"Highest Accuracy found: \", grid_mse.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "### Mini Challenge - 8\n",
    "***\n",
    "### Instructions\n",
    "* Make a prediction on the test dataset and print the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6510204081632653"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = grid_mse.predict(x_test)\n",
    "accuracy_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/quiz.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "# Gradient Boosting Machines\n",
    "***\n",
    "```python\n",
    "Q1. Which of the following is true about “max_depth” hyperparameter in Gradient Boosting?\n",
    "\n",
    "Lower is better parameter in case of same validation accuracy\n",
    "Higher is better parameter in case of same validation accuracy\n",
    "Increase the value of max_depth may overfit the data\n",
    "Increase the value of max_depth may underfit the data\n",
    "A) 1 and 3\n",
    "B) 1 and 4\n",
    "C) 2 and 3\n",
    "D) 2 and 4\n",
    "\n",
    "\n",
    "```\n",
    "```python\n",
    "Q2. Which of the following algorithm doesn’t uses learning Rate as of one of its hyperparameter?\n",
    "\n",
    "Gradient Boosting\n",
    "Extra Trees\n",
    "AdaBoost\n",
    "Random Forest\n",
    "A) 1 and 3\n",
    "B) 1 and 4\n",
    "C) 2 and 3\n",
    "D) 2 and 4\n",
    "\n",
    "\n",
    "```\n",
    "```python\n",
    "Q3. Which of the following is true about the Gradient Boosting trees?\n",
    "\n",
    "In each stage, introduce a new regression tree to compensate the shortcomings of existing model\n",
    "We can use gradient decent method for minimize the loss function\n",
    "A) 1\n",
    "B) 2\n",
    "C) 1 and 2\n",
    "D) None of these\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "```python\n",
    "Q4. In greadient boosting it is important use learning rate to get optimum output. Which of the following is true abut choosing the learning rate?\n",
    "\n",
    "A) Learning rate should be as high as possible\n",
    "B) Learning Rate should be as low as possible\n",
    "C) Learning Rate should be low but it should not be very low\n",
    "D) Learning rate should be high but it should not be very high\n",
    "\n",
    "\n",
    "```\n",
    "```python\n",
    "Q5. [True or False] Cross validation can be used to select the number of iterations in boosting; this procedure may help reduce overfitting.\n",
    "\n",
    "A) TRUE\n",
    "B) FALSE\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Thank You\n",
    "***\n",
    "### Next Session: Clustering/ k-means\n",
    "For more queries - Reach out to academics@greyatom.com "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
